{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../learning/\")\n",
    "\n",
    "import marisa_trie\n",
    "from dataset import *\n",
    "from wikidata_linker_utils.offset_array import OffsetArray\n",
    "import train_type as tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:22: DeprecationWarning: Trie.save is deprecated and will be removed in marisa_trie 0.8.0. Please use Trie.load instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../ja_model/model.ckpt\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Dst tensor is not initialized.\n\t [[Node: save/RestoreV2_18/_31 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_106_save/RestoreV2_18\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Dst tensor is not initialized.\n\t [[Node: save/RestoreV2_18/_31 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_106_save/RestoreV2_18\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInternalError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-354db23f9464>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0malpha_type_belief\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.99\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequenceTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../ja_model/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ジャガー が ジャングル で ハンティングして いる\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0msent_splits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/deeptype/learning/train_type.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, device, faux_cudnn, rebuild_graph)\u001b[0m\n\u001b[1;32m   2367\u001b[0m                     \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2368\u001b[0m                     \u001b[0mrebuild_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrebuild_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2369\u001b[0;31m                     \u001b[0mfaux_cudnn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfaux_cudnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2370\u001b[0m                 )\n\u001b[1;32m   2371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/deeptype/learning/train_type.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, session, path, args, verbose, trainable, rebuild_graph, faux_cudnn, replace_to, replace_from)\u001b[0m\n\u001b[1;32m   1944\u001b[0m                 \u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1945\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1946\u001b[0;31m                 \u001b[0muse_metagraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1947\u001b[0m             )\n\u001b[1;32m   1948\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrelevant_props\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/deeptype/learning/train_type.py\u001b[0m in \u001b[0;36mrestore_session\u001b[0;34m(session, path, replace_to, replace_from, verbose, use_metagraph, only_features)\u001b[0m\n\u001b[1;32m   1559\u001b[0m                                 if var.name.split(':')[0] not in saved_shapes]\n\u001b[1;32m   1560\u001b[0m                 \u001b[0mparam_saver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1561\u001b[0;31m     \u001b[0mparam_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1562\u001b[0m     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializer\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmissing_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1563\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1664\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1665\u001b[0m       sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1666\u001b[0;31m                {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1667\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Dst tensor is not initialized.\n\t [[Node: save/RestoreV2_18/_31 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_106_save/RestoreV2_18\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_prob(tagger_ins,sentence_splits):\n",
    "    ps = tagger_ins.predict_proba_sentences([sentence_splits])\n",
    "    output = [i for i in ps]\n",
    "    probs = output[0]['type']\n",
    "    return probs[0]\n",
    "\n",
    "language_path = \"../data/ja_trie/\"\n",
    "\n",
    "trie_index2indices_values = OffsetArray.load(\n",
    "    join(language_path, \"trie_index2indices\")\n",
    ")\n",
    "trie_index2indices_counts = OffsetArray(\n",
    "    np.load(join(language_path, \"trie_index2indices_counts.npy\")),\n",
    "    trie_index2indices_values.offsets\n",
    ")\n",
    "\n",
    "trie = marisa_trie.Trie().load(\n",
    "    join(language_path, \"trie.marisa\")\n",
    ")\n",
    "\n",
    "mention = \"ジャガー\"\n",
    "\n",
    "min_prob = 0.01\n",
    "anchor = trie.get(mention)\n",
    "indices = trie_index2indices_values[anchor]\n",
    "link_probs = trie_index2indices_counts[anchor]\n",
    "link_probs = link_probs / link_probs.sum()\n",
    "mask = link_probs > min_prob\n",
    "indices = indices[mask]\n",
    "link_probs = link_probs[mask]\n",
    "\n",
    "alpha_type_belief = 0.5\n",
    "beta = 0.99\n",
    "tagger = tp.SequenceTagger('../ja_model/')\n",
    "sentence = \"ジャガー が ジャングル で ハンティングして いる\"\n",
    "sent_splits = sentence.split()\n",
    "model_probs = get_prob(tagger,sent_splits)\n",
    "token_location = sent_splits.index(mention)\n",
    "type_belief = model_probs[token_location]\n",
    "\n",
    "type_oracle = load_oracle_classification(\"../data/classifications/type_classification\")\n",
    "assignments = type_oracle.classify(indices)\n",
    "type_probs = type_belief[assignments]\n",
    "type_probs = alpha_type_belief * type_probs + (1.0 - alpha_type_belief)\n",
    "\n",
    "full_score = link_probs * (1.0 - beta + beta * type_probs)\n",
    "\n",
    "index = full_score.argmax()\n",
    "top_pick = indices[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22728920"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_pick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Trie.save is deprecated and will be removed in marisa_trie 0.8.0. Please use Trie.load instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "t2w = marisa_trie.Trie().load(\n",
    "    \"../data/wikidata/wikititle2wikidata.marisa\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b34e7e527b97445587f6b01969a342eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm import tqdm_notebook\n",
    "out = defaultdict(dict)\n",
    "with open(\"../data/wikidata/wikidata_wikititle2wikidata.tsv\") as f:\n",
    "    for line in tqdm_notebook(f):\n",
    "        it = line.replace('\\n', '').split('\\t')\n",
    "        target = 'wiki/'\n",
    "        start = it[0].index(target)\n",
    "        end = start + len(target)\n",
    "        k, v = it[0][:start], it[0][end:]\n",
    "        if(k in ['en', 'ja']):\n",
    "            out[int(it[1])][k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'Northern Ireland', 'ja': '北アイルランド'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"../data/wikidata/indices2title.pkl\", 'wb') as f:\n",
    "    pickle.dump(out, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"../data/wikidata/indices2title.pkl\", 'rb') as f:\n",
    "    out = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ミック・ジャガー\n",
      "ジャガー (駆逐艦)\n",
      "フェンダー・ジャガー\n",
      "ジャガー (自動車)\n",
      "ジャガー\n",
      "ジャガー・レーシング\n",
      "ジャガー (ローカルタレント)\n",
      "ジャガー (西城秀樹の曲)\n"
     ]
    }
   ],
   "source": [
    "for index in indices:\n",
    "    print(out[index]['ja'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ar': 'جاغوار (شركة)',\n",
       " 'ast': 'Xaguar Cars',\n",
       " 'az': 'Jaguar (avtomobil)',\n",
       " 'be_x_old': 'Jaguar Cars',\n",
       " 'bg': 'Ягуар (кола)',\n",
       " 'bs': 'Jaguar (automobil)',\n",
       " 'ca': 'Jaguar Cars',\n",
       " 'ckb': 'جاگوار (ئۆتۆمبێل)',\n",
       " 'commons': 'Jaguar (automobile)',\n",
       " 'cs': 'Jaguar',\n",
       " 'da': 'Jaguar Cars',\n",
       " 'de': 'Jaguar Cars',\n",
       " 'en': 'Jaguar Cars',\n",
       " 'eo': 'Jaguar',\n",
       " 'es': 'Jaguar Cars',\n",
       " 'eu': 'Jaguar Cars',\n",
       " 'fa': 'جگوار کارز',\n",
       " 'fi': 'Jaguar',\n",
       " 'fr': 'Jaguar (automobile)',\n",
       " 'gl': 'Jaguar Cars',\n",
       " 'he': 'יגואר (יצרן רכב)',\n",
       " 'hi': 'जैगुआर कारें',\n",
       " 'hr': 'Jaguar (automobil)',\n",
       " 'hu': 'Jaguar Cars',\n",
       " 'hy': 'Jaguar',\n",
       " 'id': 'Jaguar (perusahaan otomotif)',\n",
       " 'it': 'Jaguar',\n",
       " 'ja': 'ジャガー (自動車)',\n",
       " 'kk': 'Jaguar',\n",
       " 'kn': 'ಜಗ್ವಾರ್ ಕಾರ್ ಗಳು',\n",
       " 'ko': '재규어 자동차',\n",
       " 'ku': 'Jaguar Cars',\n",
       " 'ln': 'Jaguar',\n",
       " 'lt': 'Jaguar Cars',\n",
       " 'lv': 'Jaguar Cars',\n",
       " 'ml': 'ജാഗ്വാർ കാറുകൾ',\n",
       " 'mr': 'जॅग्वार कार्स',\n",
       " 'nah': 'Jaguar',\n",
       " 'nl': 'Jaguar Cars',\n",
       " 'no': 'Jaguar (bil)',\n",
       " 'pl': 'Jaguar (motoryzacja)',\n",
       " 'pt': 'Jaguar Cars',\n",
       " 'ro': 'Jaguar Cars',\n",
       " 'ru': 'Jaguar',\n",
       " 'sco': 'Jaguar Cars',\n",
       " 'sh': 'Jaguar Cars',\n",
       " 'simple': 'Jaguar Cars',\n",
       " 'sk': 'Jaguar',\n",
       " 'sr': 'Јагуар аутомобили',\n",
       " 'sv': 'Jaguar (bilmärke)',\n",
       " 'ta': 'சியாகுவார் தானுந்துகள்',\n",
       " 'th': 'จากัวร์ (รถยนต์)',\n",
       " 'tr': 'Jaguar Cars',\n",
       " 'uk': 'Jaguar',\n",
       " 'zh': '捷豹'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[top_pick]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2], [3, 4], [5, 6], [4, 5, 6], [5, 6, 7]]\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter \n",
    "ts = ['BC', 'DE', 'EF', 'EEF', 'EFE']\n",
    "ss = ['A','B','C','D','E','E','F','E']\n",
    "con = [[] for t in ts]\n",
    "fin = [False for t in ts]\n",
    "sep = ''\n",
    "for i, s in enumerate(ss):\n",
    "    for j, t in enumerate(ts):\n",
    "        if fin[j] is True:\n",
    "            continue            \n",
    "        if con[j]:\n",
    "            tmp = list(itemgetter(*con[j])(ss))\n",
    "            tmp = tmp + [ss[i]]\n",
    "            ndl = sep.join(tmp)                \n",
    "        else:\n",
    "            ndl = ss[i]\n",
    "        if ndl == t:\n",
    "            con[j].append(i)\n",
    "            fin[j] = True\n",
    "        elif t.startswith(ss[i]) and not t.startswith(ndl):\n",
    "            con[j] = [i]\n",
    "            if ss[i] == t:\n",
    "                fin[j] = True\n",
    "        elif t.startswith(ndl):\n",
    "            con[j].append(i)\n",
    "        else:\n",
    "            con[j] = []\n",
    "\n",
    "print(con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1, 2], [3, 4], [5, 6]], [[4, 5, 6]], [[5, 6, 7]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "con_s = con[:]\n",
    "stack_list = []\n",
    "\n",
    "def is_all_none(arr):\n",
    "    for a in arr:\n",
    "        if a is not None:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "while(not is_all_none(con_s)):\n",
    "    appeared_value = []\n",
    "    appeared_index = []\n",
    "    stack = []\n",
    "    for i, c in enumerate(con_s):\n",
    "        if c is None:\n",
    "            continue\n",
    "        if np.sum(np.in1d(c, appeared_value)) > 0:\n",
    "            continue\n",
    "        else:\n",
    "            stack.append(c)\n",
    "            appeared_index.append(i)\n",
    "            for v in c:\n",
    "                appeared_value.append(v)\n",
    "    for index in appeared_index:\n",
    "        con_s[index] = None\n",
    "    stack_list.append(stack)\n",
    "    \n",
    "print(stack_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('en', 'Category:WikiProject Intertranswiki/Croatian')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_line = \"enwiki/Category:WikiProject Intertranswiki/Croatian\"\n",
    "target = 'wiki/'\n",
    "start = the_line.index(target)\n",
    "end = start + len(target)\n",
    "\n",
    "the_line[:start], the_line[end:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Trie.save is deprecated and will be removed in marisa_trie 0.8.0. Please use Trie.load instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import marisa_trie\n",
    "from os.path import join \n",
    "language_path = \"../data/en_trie/\"\n",
    "\n",
    "trie = marisa_trie.Trie().load(\n",
    "    join(language_path, \"trie.marisa\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8831347"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trie.get(\"Franz Fischler\".lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Trie.save is deprecated and will be removed in marisa_trie 0.8.0. Please use Trie.load instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "language_path = \"../data/ja_trie/\"\n",
    "\n",
    "trie = marisa_trie.Trie().load(\n",
    "    join(language_path, \"trie.marisa\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trie.get('アメリカ中央情報局') is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-41516e200beb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mtrie\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CIA'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert trie.get('CIA') is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
